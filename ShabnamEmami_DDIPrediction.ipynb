{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from MainExample import DeepMDA\n",
    "import snf\n",
    "# matplotlib.use('agg')\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib\n",
    "# from keras.layers.core import Dropout, Activation\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, InputLayer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.python.keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Generate list of drug names, like : ['drug1', 'drug2', ....] \n",
    "def get_drug_name_list():\n",
    "    drug_name_list = list()\n",
    "    for index in range(1, 549):\n",
    "        drug_name_list.append(\"drug\" + str(index))\n",
    "    return drug_name_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T19:12:30.703487400Z",
     "start_time": "2024-07-20T19:12:30.691135300Z"
    }
   },
   "id": "ac98f3ff5e948ef6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read similarity matrix file and return as numpy array\n",
    "def read_similarity_matrix(path: str):\n",
    "    #drug_name_list = get_drug_name_list()\n",
    "    df = pd.read_csv(path, index_col=False, header=None, dtype=np.float64)\n",
    "    return df.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d1dfaeccc2c232a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finds the candidate drugs of clustering\n",
    "def find_candidate(_embeddings, _kmeans):\n",
    "    centroids = _kmeans.cluster_centers_\n",
    "    closest, _ = pairwise_distances_argmin_min(centroids, _embeddings)\n",
    "\n",
    "    # Central samples of each cluster\n",
    "    central_samples = _embeddings[closest]\n",
    "\n",
    "    indices = np.zeros(len(central_samples))\n",
    "    for i in range(len(central_samples)):\n",
    "        tmp, _ = np.where(np.isclose(central_samples[i], _embeddings))\n",
    "        indices[i] = tmp[0]\n",
    "\n",
    "    return list(indices.astype(int))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86c234554200b4f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Does the clustering or grouping of dataset\n",
    "def make_groups(_embeddings, group_count):\n",
    "    _kmeans = KMeans(n_clusters=group_count)  # Adjust the number of clusters as needed\n",
    "    return _kmeans.fit_predict(_embeddings), _kmeans"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6421abf69822759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare the input data for Neural network\n",
    "def prepare_data(candidates=None, seperate=False):\n",
    "    # Uncomment for DS1\n",
    "    drug_fea = np.loadtxt(\"NDD/DS1/IntegratedDS1.txt\",dtype=float,delimiter=\",\")\n",
    "    interaction = np.loadtxt(\"NDD/DS1/drug_drug_matrix.csv\",dtype=int,delimiter=\",\")\n",
    "    # Uncomment for DS2\n",
    "    # drug_fea = pd.read_csv(\"NDD/DS2/simMatrix.csv\", index_col=False, header=None, dtype=np.float64).to_numpy()\n",
    "    # interaction = pd.read_csv(\"NDD/DS2/ddiMatrix.csv\",index_col=False, header=None, dtype=np.int32).to_numpy()\n",
    "\n",
    "    train = []\n",
    "    label = []\n",
    "    tmp_fea=[]\n",
    "    drug_fea_tmp = []\n",
    "    for i in range(0, interaction.shape[0]):\n",
    "        for j in range(0, interaction.shape[1]):\n",
    "            if i in candidates and j in candidates:     # added by sbn\n",
    "                label.append(interaction[i,j])\n",
    "                drug_fea_tmp = list(drug_fea[i])\n",
    "                if seperate:\n",
    "\n",
    "                     tmp_fea = (drug_fea_tmp,drug_fea_tmp)\n",
    "\n",
    "                else:\n",
    "                     tmp_fea = drug_fea_tmp + drug_fea_tmp\n",
    "                train.append(tmp_fea)\n",
    "    return np.array(train), label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3874e5f5164357d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function for computing performance of Neural network\n",
    "def calculate_performace(test_num, pred_y,  labels):\n",
    "    tp =0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] ==1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp +1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn +1\n",
    "            else:\n",
    "                fp = fp + 1 \n",
    "    acc = float(tp + tn)/test_num\n",
    "    if tp == 0 and fp == 0:\n",
    "        precision = 0\n",
    "        MCC = 0\n",
    "        sensitivity = float(tp)/ (tp+fn)\n",
    "        specificity = float(tn)/(tn + fp)\n",
    "    else:\n",
    "        precision = float(tp)/(tp+ fp)\n",
    "        sensitivity = float(tp)/ (tp+fn)\n",
    "        specificity = float(tn)/(tn + fp)\n",
    "        MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    return acc, precision, sensitivity, specificity, MCC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3752209ad521b347"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Changes the format of input data to Neural network\n",
    "def transfer_array_format(data):\n",
    "    formated_matrix1 = []\n",
    "    formated_matrix2 = []\n",
    "    for val in data:\n",
    "        formated_matrix1.append(val[0])\n",
    "        formated_matrix2.append(val[1])\n",
    "    return np.array(formated_matrix1), np.array(formated_matrix2)\n",
    "\n",
    "# Preprocess the labels\n",
    "def preprocess_labels(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "        y = encoder.transform(labels).astype(np.int32)\n",
    "    if categorical:\n",
    "        y = np_utils.to_categorical(y)\n",
    "    return y, encoder\n",
    "# Preprocess the names\n",
    "def preprocess_names(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "    if categorical:\n",
    "        labels = np_utils.to_categorical(labels)\n",
    "    return labels, encoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1333cb5a30b7dd9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate the model object\n",
    "def NDD(input_dim): \n",
    "    # model = Sequential()\n",
    "    # model.add(Dense(input_dim=input_dim, output_dim=400,init='glorot_normal'))\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(Dense(input_dim=400, output_dim=300,init='glorot_normal'))\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(Dense(input_dim=300, output_dim=2,init='glorot_normal'))\n",
    "    # model.add(Activation('sigmoid'))\n",
    "    # sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "    # return model\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(400, input_dim=input_dim, kernel_initializer='glorot_normal'),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(300, kernel_initializer='glorot_normal'),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, kernel_initializer='glorot_normal'),\n",
    "        Activation('sigmoid')\n",
    "    ])\n",
    "    # sgd = optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    sgd = optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df620457426e2489"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Main function for executing Neural network\n",
    "def DeepMDA(candidates=None):\n",
    "    X, labels = prepare_data(candidates, seperate = True)\n",
    "\n",
    "    X_data1, X_data2 = transfer_array_format(X) \n",
    "    X=0\n",
    "    y, encoder = preprocess_labels(labels)# labels labels_new\n",
    "    X= np.concatenate((X_data1, X_data2), axis = 1)\n",
    "    num = np.arange(len(y))\n",
    "    np.random.shuffle(num)\n",
    "    X_data1 = X_data1[num]\n",
    "    X_data2 = X_data2[num]\n",
    "    y = y[num]\n",
    "    num_cross_val = 5\n",
    "    all_performance_DNN = []\n",
    "    for fold in range(num_cross_val):\n",
    "        train_label = np.array([x for i, x in enumerate(y) if i % num_cross_val != fold])\n",
    "        test_label = np.array([x for i, x in enumerate(y) if i % num_cross_val == fold])\n",
    "        train1 = np.array([x for i, x in enumerate(X_data1) if i % num_cross_val != fold])\n",
    "        test1 = np.array([x for i, x in enumerate(X_data1) if i % num_cross_val == fold])\n",
    "        train2 = np.array([x for i, x in enumerate(X_data2) if i % num_cross_val != fold])\n",
    "        test2 = np.array([x for i, x in enumerate(X_data2) if i % num_cross_val == fold])\n",
    "     \n",
    "        zerotest=0\n",
    "        nozerotest=0\n",
    "        zerotrain=0\n",
    "        nozerotrain=0\n",
    "        real_labels = []\n",
    "        for val in test_label:\n",
    "            if val[0] == 1:\n",
    "                nozerotest=nozerotest+1\n",
    "                real_labels.append(1)\n",
    "            else:\n",
    "                zerotest=zerotest+1\n",
    "                real_labels.append(0)\n",
    "        train_label_new = []\n",
    "        for val in train_label:\n",
    "            if val[0] == 1:\n",
    "                zerotrain=zerotrain+1\n",
    "                train_label_new.append(1)\n",
    "            else:\n",
    "                nozerotrain=nozerotrain+1\n",
    "                train_label_new.append(0)\n",
    "       \n",
    "        prefilter_train = np.concatenate((train1, train2), axis = 1)\n",
    "        prefilter_test = np.concatenate((test1, test2), axis = 1)\n",
    "        \n",
    "        model_DNN = NDD(prefilter_train.shape[1])\n",
    "        train_label_new_forDNN = np.array([[0,1] if i == 1 else [1,0] for i in train_label_new])\n",
    "\n",
    "        model_DNN.fit(prefilter_train,train_label_new_forDNN,batch_size=100,epochs=20,shuffle=True,validation_split=0)\n",
    "        # proba = model_DNN.predict_classes(prefilter_test,batch_size=200,verbose=True)\n",
    "        proba = np.argmax(model_DNN.predict(prefilter_test, batch_size=200, verbose=1), axis=1)\n",
    "        # ae_y_pred_prob = model_DNN.predict_proba(prefilter_test,batch_size=200,verbose=True)\n",
    "        ae_y_pred_prob = model_DNN.predict(prefilter_test,batch_size=200,verbose=True)\n",
    "        acc, precision, sensitivity, specificity, MCC = calculate_performace(len(real_labels), proba,  real_labels)\n",
    "        fpr, tpr, auc_thresholds = roc_curve(real_labels, ae_y_pred_prob[:,1])\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        precision1, recall, pr_threshods = precision_recall_curve(real_labels, ae_y_pred_prob[:,1])\n",
    "        aupr_score = auc(recall, precision1)\n",
    "        all_F_measure=np.zeros(len(pr_threshods))\n",
    "        for k in range(0,len(pr_threshods)):\n",
    "\n",
    "           if (precision1[k]+precision1[k])>0:\n",
    "              all_F_measure[k]=2*precision1[k]*recall[k]/(precision1[k]+recall[k])\n",
    "           else:\n",
    "              all_F_measure[k]=0\n",
    "\n",
    "        max_index=all_F_measure.argmax()\n",
    "        predicted_score=np.zeros(len(real_labels))\n",
    "        threshold=pr_threshods[max_index]\n",
    "        p=ae_y_pred_prob[:,1]\n",
    "        predicted_score[p>threshold]=1\n",
    "        f=f1_score(real_labels,predicted_score)\n",
    "        recall=recall_score(real_labels, predicted_score)\n",
    "        precision1=precision_score(real_labels, predicted_score)\n",
    "        print(\"RAW DNN:\",recall, precision1,'auc:', auc_score,'aupr', aupr_score,f)\n",
    "        all_performance_DNN.append([recall,precision1,auc_score,aupr_score,f])\n",
    "    print('recall,precision,auc_score,aupr_score,fscore')\n",
    "    print(np.mean(np.array(all_performance_DNN), axis=0))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34248d9999c44e20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_list = [\n",
    "    # \"NDD/DS1/chem_Jacarrd_sim.csv\",\n",
    "    # \"NDD/DS1/drug_drug_matrix.csv\",\n",
    "    \"NDD/DS1/enzyme_Jacarrd_sim.csv\",\n",
    "    # \"NDD/DS1/indication_Jacarrd_sim.csv\",\n",
    "    \"NDD/DS1/offsideeffect_Jacarrd_sim.csv\",\n",
    "    \"NDD/DS1/pathway_Jacarrd_sim.csv\",\n",
    "    \"NDD/DS1/sideeffect_Jacarrd_sim.csv\",\n",
    "    # \"NDD/DS1/target_Jacarrd_sim.csv\",\n",
    "    # \"NDD/DS1/transporter_Jacarrd_sim.csv\",\n",
    "    \"NDD/DS1/integratedDS1.txt\",\n",
    "    \"NDD/DS2/simMatrix.csv\"\n",
    "]\n",
    "\n",
    "# Main cell\n",
    "similarity_matrix = read_similarity_matrix(path_list[-2])\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed')\n",
    "embeddings = mds.fit_transform(similarity_matrix)\n",
    "labels, kmeans = make_groups(embeddings, 300)\n",
    "candidates = find_candidate(embeddings, kmeans)\n",
    "DeepMDA(candidates)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edf6cc61c18c694e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
